{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage.interpolation as interp\n",
    "from astropy.stats import mad_std\n",
    "from astropy.stats import sigma_clip\n",
    "from photutils.utils import calc_total_error\n",
    "import astropy.stats as stat\n",
    "from photutils import aperture_photometry, CircularAperture, CircularAnnulus, DAOStarFinder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astropy.io import fits \n",
    "import os \n",
    "import glob \n",
    "import scipy.ndimage.interpolation as interp\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "from dred import Calibration\n",
    "import dred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Reduction Module - DRED\n",
    "\n",
    "In this notebook, I outline the steps for reducing astronomical data collected with the half degree imager. This notebook utilizes the module 'dred', which can handle the bias subtraction and flatfielding steps in the reduction process. Before using dred, ensure that the paths to your data are all hardcoded based on data type e.g. a path for biases and a path for flats. Once this step is completed, you can begin the reduction process by creating an instance of the class 'Calibration'. Once the user specifies the type of calibration frames they'll be dealing with, they can create a 'master' or median combination of those frames, and apply it to their data. **Note, that the master created is different depending on the calibration frame type.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping all the Data into their Respective Folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the files\n",
    "all_filenames = glob.glob(\"Checkin1_BiasFlats/*.fits\")\n",
    "all_files = [f.split('/')[-1] for f in all_filenames]\n",
    "\n",
    "#Sorting the files by type\n",
    "for f in all_files:\n",
    "    dred.filesorter(f, 'Flats', 'Twilight Flat V', 'OBJECT', current_path = \"Checkin1_BiasFlats\")\n",
    "    dred.filesorter(f, 'Orion_V', '+05', 'RASTRNG', current_path = \"Checkin1_BiasFlats\")\n",
    "    dred.filesorter(f, 'Bias', 'Bias Frame', 'OBJECT', current_path = \"Checkin1_BiasFlats\")\n",
    "    \n",
    "#Set your own file paths\n",
    "path_to_flats = glob.glob('Checkin1_BiasFlats/Flats/*.fits')\n",
    "\n",
    "path_to_bias = glob.glob('Checkin1_BiasFlats/Bias/*.fits')\n",
    "\n",
    "path_to_orion = glob.glob('Checkin1_BiasFlats/Orion_V/*.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Subtraction\n",
    "\n",
    "In order to bias subtract our data, we must first create an instance of Calibration. In this example, I call that instance bias_calibration. Using generate_master with a 'bias' calibration type will create a master bias that is the median combination of all the individual bias frames (input as a list). When we \"apply\" it to a list of science and flat frames, an overscan value is computed for each frame in the input list, and the master bias is scaled accordingly for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of calibration for bias'\n",
    "bias_calibration = Calibration('bias')\n",
    "\n",
    "#Generating a master bias (median combination)\n",
    "bias_calibration.generate_master(path_to_bias)\n",
    "\n",
    "#Bias subtract the master bias frame from science images and flats (accounting for overscan)\n",
    "bias_calibration.apply(path_to_orion, save = True, output_dir = 'Checkin1_BiasFlats/Orion_V/')\n",
    "bias_calibration.apply(path_to_flats, save = True, output_dir = 'Checkin1_BiasFlats/Flats/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatfielding\n",
    "\n",
    "Now that we have our bias subtracted flats and science images, we can use the same methods to now flatfield the data. This time when 'generate_master' is called, it will create create a median combination of all the input flat frames, but alse normalize that median combined flat by its median pixel value, resulting in a ***different*** master frame. Then, when we apply the master flat frame to the data, it will divide all the input science frames by the master flat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing all the bias subtracted science frames\n",
    "b_sub_flats = glob.glob('Checkin1_BiasFlats/Flats/b_*.fits')\n",
    "b_sub_orion = glob.glob('Checkin1_BiasFlats/Orion_V/b_*.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dred.Calibration.MasterImage at 0x7f7f394ee810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flatfielding\n",
    "flat_calibration = Calibration('flats')\n",
    "flat_calibration.generate_master(b_sub_flats)\n",
    "flat_calibration.apply(b_sub_orion, save = True, output_dir = 'Checkin1_BiasFlats/Orion_V/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
